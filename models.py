import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import pickle

# G√©n√©ration de donn√©es factices
np.random.seed(42)
n_samples = 1000

data = pd.DataFrame({
    "age": np.random.randint(18, 80, n_samples),
    "revenu": np.random.randint(1000, 10000, n_samples),
    "dette": np.random.randint(0, 15000, n_samples),
    "historique_credit": np.random.choice(["Mauvais", "Moyen", "Bon"], n_samples),
    "nombre_cartes": np.random.randint(0, 10, n_samples),
    "credit_accepte": np.random.choice([0, 1], n_samples, p=[0.4, 0.6])  # 0 = refus√©, 1 = accept√©
})

# Encodage de la variable cat√©gorielle "historique_credit"
historique_map = {"Mauvais": 0, "Moyen": 1, "Bon": 2}
data["historique_credit"] = data["historique_credit"].map(historique_map)

# S√©paration des features et de la cible
X = data.drop(columns=["credit_accepte"])
y = data["credit_accepte"]

# Division en ensemble d'entra√Ænement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entra√Ænement du mod√®le RandomForest
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Pr√©diction et √©valuation
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"üéØ Accuracy du mod√®le : {accuracy * 100:.2f}%")

# Sauvegarde du mod√®le
with open("credit_scoring_model.pkl", "wb") as file:
    pickle.dump(model, file)

print("‚úÖ Mod√®le sauvegard√© sous 'credit_scoring_model.pkl'")
